{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Kaggle Data Science Project:</h2></center>\n",
    "<center><h1>[Insert name]</h1></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataapplab.com/wp-content/uploads/2016/10/kaggle-logo-transparent-300.png\" style=\"width: 30rem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents:\n",
    "0. [Prerquisites;](#prerequisites)\n",
    "1. [Acquisition;](#acquisition)\n",
    "2. [Exploration & Preprocessing;](#exploration-preprocessing)\n",
    "3. [Analysis;](#analysis)\n",
    "4. [Interpretation;](#interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"prerequisites\">1. Prerequisites:</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data science tools:\n",
    "\n",
    "!rm -rf ./cornelia\n",
    "!git clone -b cornelia https://github.com/augustinasn/_data_science_projects.git ./cornelia\n",
    "!rm -rf ./cornelia/.rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ZJNQ7VUjd1GD",
    "outputId": "65b8cbd0-1286-427b-b50f-17556ba7799b"
   },
   "outputs": [],
   "source": [
    "# Packages:\n",
    "\n",
    "from cornelia.imports import *\n",
    "from cornelia.helpers import display_opts\n",
    "from cornelia.extraction import read_feather, pickle_obj, unpickle_obj\n",
    "from cornelia.preprocessing import match_cols, drop_cols, fill_NAs, one_hot_encode, category_encode, split_df, drop_NAs\n",
    "from cornelia.visualization import print_missing_data, print_descriptive_stats, print_categories, plot_data, print_df, plot_distributions, pretty_print_dict\n",
    "from cornelia.analysis import score_regr, score_class, feature_importance, confidence, similiar_features, score_with_cols_dropped, pdps, Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "# Options:\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "display_opts(decimal_numbers=2,\n",
    "             max_rows=1000,\n",
    "             max_cols=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"acquisition\">1. Acquisition</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HQ8SXd2zBbE"
   },
   "outputs": [],
   "source": [
    "# Load raw data:\n",
    "\n",
    "raw_train_df = pd.read_csv(\"\")\n",
    "raw_test_df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"exploration-preprocessing\">2. Exploration and Preprocessing:</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Match columns:\n",
    "\n",
    "raw_train_df = match_cols(df1=raw_train_df,\n",
    "                          df2=raw_test_df,\n",
    "                          omit=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Observe missing data:\n",
    "\n",
    "print_missing_data(dfs=[raw_train_df, raw_test_df],\n",
    "                   labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Descriptive stats:\n",
    "\n",
    "print_descriptive_stats(dfs=[raw_train_df, raw_test_df],\n",
    "                        labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distributions\n",
    "\n",
    "plot_distributions(df=raw_train_df,\n",
    "                   target=\"y\",\n",
    "                   n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print histograms for each feature:\n",
    "    \n",
    "plot_data(dfs=[raw_train_df, raw_test_df],\n",
    "          labels=[\"train\", \"test\"],\n",
    "          bench=1,\n",
    "          n_bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup data:\n",
    "\n",
    "pickle_obj([raw_train_df, raw_test_df], \"train_test_dfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"analysis\">3. Analysis & Interpretation:</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbackup data:\n",
    "\n",
    "raw_train_df, raw_test_df = unpickle_obj(\"train_test_dfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Iteration #1 - test dropping NaNs on each axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_1 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"drop\",\n",
    "                    \"params\": {\"axis\": [0, 1]}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"split\": 0.5,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_1, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Iteration #2 - test filling NaNs with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_2 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": [\"median\", \"mean\", None],\n",
    "                               \"cat_method\": [\"mode\", None],\n",
    "                               \"was_missing\": [True, False]}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"split\": 0.5,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_2, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print score history:\n",
    "\n",
    "p.scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Iteration #3 - testing OneHotEncoding & feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_3 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": \"median\",\n",
    "                               \"cat_method\": \"mode\",\n",
    "                               \"was_missing\": True}},\n",
    "            \"categoricals\": {\"mode\": \"one_hot_encode\",\n",
    "                             \"params\": {\"card_threshold\": 15}},\n",
    "            \"split\": 0.5,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_3, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\",\n",
    "             backup=True)\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "\n",
    "fi_cols_to_drop = p.feature_importance()\n",
    "\n",
    "# Backup feature importance result:\n",
    "\n",
    "pickle_obj(fi_cols_to_drop, \"iteration_3_fi_cols_to_drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Iteration #4 - dropping unimportant features + testing colinear features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_cols_to_drop = unpickle_obj(\"fi_cols_to_drop\")\n",
    "\n",
    "config_4 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": \"median\",\n",
    "                               \"cat_method\": \"mode\",\n",
    "                               \"was_missing\": True}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"drop_cols\": fi_cols_to_drop,\n",
    "            \"split\": 0.5,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_2, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find colinear features:\n",
    "\n",
    "p.colinear_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dropping any of colinear feature will impact score:\n",
    "\n",
    "potentially_colinear_features = [[\"yearly_income=>was_missing\", \"credit_score=>was_missing\"],\n",
    "                                 [\"max_open_credit\", \"credit_balance\"],\n",
    "                                 [\"monthly_debt\", \"yearly_income\"]]\n",
    "\n",
    "# Backup feature importance result:\n",
    "\n",
    "pickle_obj(potentially_colinear_features, \"iteration_4_potentially_colinear_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Iteration #5 - test dropping different combinations of colinear features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_cols_to_drop = unpickle_obj(\"fi_cols_to_drop\")\n",
    "potentially_colinear_features = unpickle_obj(\"model_4_potentially_colinear_features\")\n",
    "feature_pairs_drop = list(itertools.product(*[t + [None] for t in potentially_colinear_features]))\n",
    "\n",
    "\n",
    "config_5 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": \"median\",\n",
    "                               \"cat_method\": \"mode\",\n",
    "                               \"was_missing\": True}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"drop_cols\": fi_cols_to_drop + feature_pairs_drop,\n",
    "            \"split\": 0.5,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_5, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colinear_features = [\"yearly_income=>was_missing\", \"max_open_credit\", \"monthly_debt\"]\n",
    "pickle_obj(colinear_features, \"iteration_5_colinear_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Iteration #6 - dropping colinear features and testing different splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_cols_to_drop = unpickle_obj(\"fi_cols_to_drop\")\n",
    "colinear_features = unpickle_obj(\"iteration_5_colinear_features\")\n",
    "\n",
    "config_6 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": \"median\",\n",
    "                               \"cat_method\": \"mode\",\n",
    "                               \"was_missing\": True}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"drop_cols\": fi_cols_to_drop + feature_pairs_drop,\n",
    "            \"split\": 0.9,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": 40}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_6, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Iteration #7 - RandomForrest parameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_cols_to_drop = unpickle_obj(\"fi_cols_to_drop\")\n",
    "colinear_features = unpickle_obj(\"iteration_5_colinear_features\")\n",
    "\n",
    "config_7 = {\"sample\": 0.2,\n",
    "            \"nas\": {\"mode\": \"fill\",\n",
    "                    \"params\": {\"num_method\": [\"median\", \"mean\", None],\n",
    "                               \"cat_method\": [\"mode\", None],\n",
    "                               \"was_missing\": [True, False]}},\n",
    "            \"categoricals\": {\"mode\": \"category_encode\"},\n",
    "            \"drop_cols\": fi_cols_to_drop + feature_pairs_drop,\n",
    "            \"split\": 0.9,\n",
    "            \"prediction\": {\"model\": \"rf\",\n",
    "                           \"params\": {\"n_estimators\": [50, 75, 100, 150],\n",
    "                                      \"max_samples\": [50_000, 100_000, 250_000],\n",
    "                                      \"max_features\": [0.7, 0.8, 0.9],\n",
    "                                      \"min_samples_leaf\": [1, 3, 5]}\n",
    "                           }\n",
    "           }\n",
    "\n",
    "p = Pipeline(config=config_7, \n",
    "             train_df=raw_train_df,\n",
    "             test_df=raw_test_df,\n",
    "             target=\"y\")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence of predictions for each feature and it's each category:\n",
    "\n",
    "confidence(model=m,\n",
    "           df=valid_X,\n",
    "           n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual relationship between independant and dependant features (partial dependance):\n",
    "\n",
    "pdps(model=m,\n",
    "          data=train_X.sample(10_000),\n",
    "          target=\"y\",\n",
    "          omit=fi_cols_to_drop + colin_cols_to_drop,\n",
    "          clusters=5)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SEB_Colab_Notebook_20201008.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
